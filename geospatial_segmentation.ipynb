{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "\n",
    "n_classes= 3 #Number of classes for segmentation\n",
    "\n",
    "# path to images and labels.\n",
    "image_dir = \"C:\\\\vision_impulse\\\\unet\\\\dlt_32N_07\\\\images\\\\\"\n",
    "label_dir = \"C:\\\\vision_impulse\\\\unet\\\\dlt_32N_07\\\\labels\\\\\"\n",
    "\n",
    "# training image info as a list\n",
    "train_images = []\n",
    "train_images_list = []\n",
    "\n",
    "mode = \"multispectral\" # multispectral or RGB as mode\n",
    "# defining start and end channel numbers to stack\n",
    "def image_mode(RasterCount, mode = mode):\n",
    "    if mode == \"multispectral\":\n",
    "        start_chnl = 1\n",
    "        end_chnl = RasterCount + 1\n",
    "        step = 1\n",
    "        channels = RasterCount\n",
    "    if mode == \"RGB\":\n",
    "        start_chnl = 4\n",
    "        end_chnl = 1\n",
    "        step = -1\n",
    "        channels = 3\n",
    "    return start_chnl, end_chnl, step, channels\n",
    "\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for img_path in glob.glob(os.path.join(root, \"*.tif\")):\n",
    "        dataset = gdal.Open(img_path)\n",
    "        start_chnl, end_chnl, step, channels = image_mode(RasterCount = dataset.RasterCount)\n",
    "        stacked = np.zeros((dataset.RasterXSize, dataset.RasterYSize, channels), int)\n",
    "        for x in range(start_chnl, end_chnl, step):\n",
    "            band = dataset.GetRasterBand(x)\n",
    "            array = band.ReadAsArray()\n",
    "            if mode == \"RGB\":\n",
    "                stacked[..., -(x-1)] = array #stack bands (4,3,2) for (R,G,B) respectively.\n",
    "            else:\n",
    "                stacked[..., x-1] = array\n",
    "            \n",
    "        img = np.reshape(stacked,(dataset.RasterXSize, dataset.RasterYSize, channels))\n",
    "        train_images.append(img)\n",
    "        train_images_list.append(img_path)    \n",
    "\n",
    "#Convert list to array for training\n",
    "train_images = np.array(train_images)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02576efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training labels info as a list\n",
    "train_masks = [] \n",
    "train_masks_list = []\n",
    "for root, dirs, files in os.walk(label_dir):\n",
    "    for mask_path in glob.glob(os.path.join(root, \"*.tif\")):\n",
    "        mask = cv2.imread(mask_path,0) \n",
    "        mask = np.array(mask)\n",
    "        train_masks_list.append(mask_path)\n",
    "        train_masks.append(mask)\n",
    "                 \n",
    "train_masks = np.array(train_masks)\n",
    "print(train_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a255168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the levels of categorical features into numeric values such as 0,1,2.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import normalize\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1,1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(train_masks_encoded_original_shape)\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "train_images = normalize(train_images, axis=1)\n",
    "\n",
    "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca66ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into train, test, and inference.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n",
    "X_train, X_inference, y_train, y_inference = train_test_split(X1, y1, test_size = 0.05, random_state = 0)\n",
    "\n",
    "print(\"total no. of train images:\",len(X_train))\n",
    "print(\"total no. of test images:\",len(y_test))\n",
    "print(\"total no. of inference images:\",len(X_inference))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e41784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the class vectors to binary matrix to use with categorical_classentropy.\n",
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import keras\n",
    "from keras.metrics import MeanIoU\n",
    "from segmentation_models import Unet\n",
    "from keras.layers import Input, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "# using ResNet as model backbone with imagenet pretrained weights\n",
    "Backbone = 'resnet34'\n",
    "preprocess_input1 = sm.get_preprocessing(Backbone)\n",
    "\n",
    "X_train1 = preprocess_input1(X_train)\n",
    "X_test1 = preprocess_input1(X_test)\n",
    "\n",
    "N = X_train.shape[3] # no. of channels\n",
    "\n",
    "inp = Input(shape=(None, None, N))\n",
    "l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n",
    "out = base_model(l1)\n",
    "\n",
    "model = Model(inp, out, name=base_model.name)\n",
    "\n",
    "#start training with previously trained model weights.\n",
    "model.load_weights('C:\\\\vision_impulse\\\\unet_sandstone\\\\test_pretrained_with_wt.hdf5') \n",
    "\n",
    "model.compile('Adam', loss='categorical_crossentropy', metrics= sm.metrics.IOUScore())\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# filepath to save training model checkpoins\n",
    "checkpoint_filepath = \"C:\\\\vision_impulse\\\\unet_sandstone\\\\model_on_RGBdata_with_pretrained_weights.hdf5\"\n",
    "\n",
    "# checkpoint callback to save model based on best validation IoU.\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                            filepath=checkpoint_filepath,\n",
    "                            save_weights_only=True,\n",
    "                            monitor='val_iou_score',\n",
    "                            mode='max',\n",
    "                            save_best_only=True)\n",
    "\n",
    "model.fit(X_train1,\n",
    "           y_train_cat,\n",
    "           batch_size = 8,\n",
    "           epochs = 60,\n",
    "           verbose = 1,\n",
    "           validation_data = (X_test1, y_test_cat),\n",
    "           callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0b4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Model\n",
    "\n",
    "# mode = \"multispectral\"\n",
    "# map N channels data to 3 channels\n",
    "if mode == \"multispectral\":\n",
    "    N = 12\n",
    "    base_model = Unet(backbone_name=Backbone, encoder_weights='imagenet', classes = n_classes, activation = 'softmax')\n",
    "\n",
    "    # map N channels data to 3 channels\n",
    "    inp = Input(shape=(None, None, X_train.shape[3]))\n",
    "    l1 = Conv2D(3, (1, 1))(inp) \n",
    "    out = base_model(l1)\n",
    "\n",
    "    model = Model(inp, out, name=base_model.name)\n",
    "    \n",
    "if mode == \"RGB\":\n",
    "    N = 3\n",
    "    model = Unet(backbone_name=Backbone, encoder_weights='imagenet', classes = n_classes, activation = 'softmax')\n",
    "\n",
    "checkpoint_filepath = \"C:\\\\vision_impulse\\\\unet_sandstone\\\\model_on_12bandsdata_with_pretrained_weights.hdf5\"\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "# prediction on random inference images\n",
    "index = np.random.randint(0, len(X_inference),1) \n",
    "pred_img = X_inference[index].reshape((1,64,64,N))\n",
    "pred_img = normalize(pred_img, axis=1)\n",
    "y_pred = model.predict(pred_img)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "\n",
    "prediction = y_pred_argmax.reshape((64,64))\n",
    "ground_truth = y_inference[index].reshape((64,64))\n",
    "\n",
    "# splitting the data to get a same inference label image.\n",
    "# from sklearn.model_selection import train_test_split\n",
    "X1_list, X_test_list, y1_list, y_test_list = train_test_split(train_images_list, train_masks_list, test_size = 0.10, random_state = 0)\n",
    "X_train_list, X_inference_list, y_train_list, y_inference_list = train_test_split(X1_list, y1_list, test_size = 0.05, random_state = 0)\n",
    "inference_image_name = np.array(y_inference_list)[index][0]\n",
    "inference_image = cv2.imread(inference_image_name)\n",
    "\n",
    "# visualization on inference images.\n",
    "print('\\033[1m' +\"\\t\\t\\t\\t\\tPredictions on \"+mode+\" mode\")\n",
    "fig, axes = plt.subplots(nrows=1,ncols=3,figsize=(12,12))\n",
    "plt.sca(axes[0]); \n",
    "plt.imshow(prediction,cmap=\"viridis\"); plt.title('prediction')\n",
    "plt.axis(\"off\")\n",
    "plt.sca(axes[1]); \n",
    "plt.imshow(ground_truth,cmap=\"viridis\"); plt.title('Ground truth')\n",
    "plt.axis(\"off\")\n",
    "plt.sca(axes[2]); \n",
    "plt.imshow(inference_image); plt.title('Label')\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
